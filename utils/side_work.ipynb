{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.        ,  75.71063741, 149.31389391, ..., 154.71535102,\n",
       "          49.67604825, 118.06726708],\n",
       "        [-26.10911452,  49.4939424 , 195.50574922, ..., 133.20360364,\n",
       "          17.03758838,  23.92387506],\n",
       "        [  0.        ,   1.        ,   1.        , ...,   1.        ,\n",
       "           1.        ,   1.        ]],\n",
       "\n",
       "       [[ 26.03094352,  83.65509044, 120.93402709, ..., 160.73603675,\n",
       "          37.24532382,  97.11380604],\n",
       "        [ 86.41022512,  63.1054386 , 178.16249727, ..., 115.75988716,\n",
       "          41.3056107 ,  31.04216451],\n",
       "        [  1.        ,   1.        ,   1.        , ...,   1.        ,\n",
       "           1.        ,   1.        ]],\n",
       "\n",
       "       [[ 50.60790641,  86.64750109, 156.43016682, ..., 187.84539463,\n",
       "          52.84619531,  63.68995822],\n",
       "        [ 75.70079791,  67.02470209, 155.32224409, ..., 116.96402431,\n",
       "          33.21626993,  31.04216451],\n",
       "        [  1.        ,   1.        ,   1.        , ...,   1.        ,\n",
       "           1.        ,   1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[139.12874857, 123.72161524, 119.35736782, ..., 125.81605954,\n",
       "          63.54348958,  70.83500815],\n",
       "        [ 89.58396778, 136.1944065 , 177.39547384, ...,  57.37550775,\n",
       "         133.47412273, 108.56729432],\n",
       "        [  1.        ,   1.        ,   1.        , ...,   1.        ,\n",
       "           1.        ,   1.        ]],\n",
       "\n",
       "       [[ 96.88513933,  84.44953575, 106.74409368, ..., 171.57327105,\n",
       "          58.04648581,  27.16189395],\n",
       "        [ 56.61143933, 106.19085555, 152.16892556, ...,  68.18019781,\n",
       "          91.87179876,  69.36318138],\n",
       "        [  1.        ,   1.        ,   1.        , ...,   1.        ,\n",
       "           1.        ,   1.        ]],\n",
       "\n",
       "       [[116.56859752,  54.65783687,  87.82418246, ..., 162.55851459,\n",
       "          63.2467763 ,  16.0295315 ],\n",
       "        [ 53.42206246,  98.4847361 , 145.05265264, ...,  51.94061847,\n",
       "         101.6945697 ,  82.28849643],\n",
       "        [  1.        ,   1.        ,   1.        , ...,   1.        ,\n",
       "           1.        ,   1.        ]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('leeds_sports_extended.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matstruct_to_pydict import generate_dataset_obj\n",
    "\n",
    "decoded1 = scipy.io.loadmat('/home/mxerri/JointPoseEstimation/Data/mpii_human_pose_v1_u12_1.mat', struct_as_record=False)[\"RELEASE\"]\n",
    "mpii_dict = generate_dataset_obj(decoded1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': {'name': '037454012.jpg'},\n",
       " 'annorect': [{'scale': 3.8807339512004684, 'objpos': {'x': 601, 'y': 380}}],\n",
       " 'frame_sec': [],\n",
       " 'vididx': []}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpii_dict.get('annolist')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_exist = np.array(mpii_dict.get('img_train'))\n",
    "people = mpii_dict.get('single_person')\n",
    "\n",
    "\n",
    "def isOne(element):\n",
    "    \"\"\"Function for map to get entries that include annotations of one one person\"\"\"\n",
    "    if element==1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "is_ones_mask = np.array(list(map(isOne, people)))\n",
    "labels_mask = np.array(labels_exist==1)\n",
    "\n",
    "#getting indices which are single person and are labelled as a boolean mask on the whole dataset \n",
    "single_training_mask = is_ones_mask & labels_mask\n",
    "single_training_mask = np.array(single_training_mask)\n",
    "\n",
    "# getting list of indices of just the entries that we can use (len ==eleven thousand something)\n",
    "indices_in_mpii = [i for i, x in enumerate(single_training_mask) if x] # this is indexed starting at 0 but matlab is not \n",
    "\n",
    "# filter out what we dont need using the mask\n",
    "annolist_numpy =np.array(mpii_dict.get('annolist'))\n",
    "annolist_trimmed = annolist_numpy[single_training_mask]\n",
    "\n",
    "# get the image names in a list\n",
    "def getName(lst):\n",
    "    \"\"\"Function for map to get image names\"\"\"\n",
    "    return (lst.get('image').get('name')) \n",
    "\n",
    "image_names = np.array(list(map(getName, annolist_trimmed)))\n",
    "# print(annolist_trimmed[0].get('annorect')[0].get('annopoints'))\n",
    "# print(annolist_trimmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18183/4013472169.py:25: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if visible == []:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11749, 14, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#_______________________________________________________________\n",
    "# get the annotations for a single picture \n",
    "def getAnnopoints(lst):\n",
    "    \"\"\"\n",
    "    This will be used in a mapping function to get the joint preditions in every image\n",
    "    \"\"\"\n",
    "    one_pic_annots = np.zeros((16,4))\n",
    "    point = lst.get('annorect')[0].get('annopoints').get('point')\n",
    "    for i in range(len(point)):\n",
    "\n",
    "        id = point[i].get('id') \n",
    "        \n",
    "        # changes into the format of leeds sports dataset\n",
    "        if id == 6 or id ==7 :\n",
    "            id = 15\n",
    "        elif id == 8 or id == 9:\n",
    "            id = id + 4\n",
    "        elif id == 10 or id == 11 or id == 12 or id == 13 or id == 14 or id == 15:\n",
    "            id = id -4\n",
    "        else:\n",
    "            id = id\n",
    "        \n",
    "        visible = point[i].get('is_visible')\n",
    "        # checks for if is visible is []\n",
    "        if visible == []:\n",
    "            visible = 0\n",
    "\n",
    "        # if there are not 16 joints all the categories for these joints will be \n",
    "        # zero as set by the np.zeros array i predefined \n",
    "\n",
    "        one_pic_annots[id] = np.array([id, point[i].get('x'),point[i].get('y'), visible])\n",
    "    one_pic_annots = np.delete(one_pic_annots, (15), axis=0)\n",
    "    one_pic_annots = np.delete(one_pic_annots, (14), axis=0)\n",
    "    one_pic_annots = np.delete(one_pic_annots, (0), axis=1)\n",
    "    return one_pic_annots\n",
    "\n",
    "annotations = list(map(getAnnopoints, annolist_trimmed))\n",
    "print(np.array(annotations).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11749,)\n",
      "(11749, 14, 3)\n"
     ]
    }
   ],
   "source": [
    "# saving the preprocessed data \n",
    "imagenames_and_annotations = [image_names, np.array(annotations)]\n",
    "\n",
    "print(image_names.shape)\n",
    "print(np.array(annotations).shape)\n",
    "\n",
    "np.save('/home/mxerri/JointPoseEstimation/datasets/mpii_annots.npy', np.array(annotations))\n",
    "np.save('/home/mxerri/JointPoseEstimation/datasets/mpii_image_names.npy', np.array(image_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
